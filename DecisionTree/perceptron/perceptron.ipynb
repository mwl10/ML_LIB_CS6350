{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "cf2d3c17-8ad5-4b10-bb90-5dcc2fd940da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(seed=1)\n",
    "np.set_printoptions(precision=7)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0765128-61a5-4710-8491-19a28dc6d7ec",
   "metadata": {},
   "source": [
    "### Process bank-note dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "cc8f5ee5-9f19-4353-83d8-7dbadb4be332",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../datasets/bank-note/train.csv', header=None).to_numpy()\n",
    "test = pd.read_csv('../datasets/bank-note/test.csv', header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "dc511e5b-359a-4bd1-803b-d529d016f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### last column is label (-1,1)\n",
    "\n",
    "x_train = train[:,:-1]\n",
    "y_train = train[:,-1]\n",
    "y_train = np.where(y_train == 0, -1,1)\n",
    "\n",
    "x_test = test[:,:-1]\n",
    "y_test = test[:,-1]\n",
    "y_test= np.where(y_test == 0, -1,1)\n",
    "\n",
    "# add column of ones to wrap in b\n",
    "x_train = np.concatenate((x_train, np.ones((x_train.shape[0],1))), axis=1)\n",
    "x_test = np.concatenate((x_test, np.ones((x_test.shape[0],1))), axis=1)\n",
    "\n",
    "shuffle = np.random.choice(len(x_train), len(x_train), replace=False)\n",
    "x_train = x_train[shuffle]\n",
    "y_train = y_train[shuffle]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0da45e-cd83-45e9-b342-764a7e505394",
   "metadata": {},
   "source": [
    "### Standard Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "743a4140-64ed-446b-a67d-b33f04aa1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "### utilities\n",
    "calc_avg_error = lambda preds,labels: (preds != labels).mean()\n",
    "predict = lambda x,w: np.sign(x @ w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "b0a87e09-683c-4f24-97ef-d691a591da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize w\n",
    "w_1 = np.zeros((x_train.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "71b58732-309a-43e6-8953-e6add816b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(x_train.shape[0]):\n",
    "        \n",
    "        pred = predict(x_train[i], w_1)\n",
    "        label = y_train[i]\n",
    "        if pred != label:\n",
    "            # if we guess negative but answer is positive, increase\n",
    "            if pred == -1:\n",
    "                w_1 += lr * x_train[i]\n",
    "            # if we guess positive but answer is negative, decrease\n",
    "            else:\n",
    "                w_1 -= lr * x_train[i]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "733f9d40-fdc5-4a4d-a64c-0567dfcdf342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STANDARD PERCEPTRON \n",
      " w_1=array([-0.0632714, -0.039825 , -0.049964 , -0.0108285,  0.048    ]),\n",
      " train_avg_error_1=0.020642201834862386,\n",
      " test_avg_error_1=0.02\n"
     ]
    }
   ],
   "source": [
    "train_preds_1 = predict(x_train,w_1)\n",
    "train_avg_error_1 = calc_avg_error(train_preds_1,y_train)\n",
    "\n",
    "test_preds_1 = predict(x_test,w_1)\n",
    "test_avg_error_1 = calc_avg_error(test_preds_1, y_test)\n",
    "\n",
    "print(f'STANDARD PERCEPTRON \\n {w_1=},\\n {train_avg_error_1=},\\n {test_avg_error_1=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fc11b8-36ce-4761-95f7-f049a9fc2ef0",
   "metadata": {},
   "source": [
    "### Voted Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "788d7fb8-236a-4a37-bdcc-85359f53c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "### utilities\n",
    "calc_avg_error = lambda preds,labels: (preds != labels).mean()\n",
    "predict = lambda x,w: np.sign(x @ w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "c8e51a73-250d-41bf-a9d6-48a7c8c61445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize w\n",
    "w_2 = np.zeros((x_train.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "a136e647-42c0-4c38-86d8-d005d7a3a1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "## have a count of number of correct answers for a w, before it is wrong and thus is updated \n",
    "\n",
    "### count number of correct \n",
    "c=1\n",
    "keeps = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(x_train.shape[0]):\n",
    "        pred = predict(x_train[i], w_2)\n",
    "        label = y_train[i]\n",
    "        if pred != label:\n",
    "            keeps.append((w_2,c))\n",
    "            # if we guess negative but answer is positive, increase\n",
    "            if pred == -1:\n",
    "                w_2 = w_2 + (lr * x_train[i])\n",
    "            # if we guess positive but answer is negative, decrease\n",
    "            else:\n",
    "                w_2 = w_2 - (lr * x_train[i])\n",
    "        \n",
    "            c = 1 \n",
    "        else:\n",
    "            c += 1\n",
    "\n",
    "def voted_predict(x,keeps):\n",
    "    sum = np.array([c * predict(x,w) for (w,c) in keeps]).sum(axis=0)\n",
    "    return np.sign(sum)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "0bcbe461-c53e-4a14-a0cc-8dd9376da7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOTED PERCEPTRON \n",
      " train_avg_error_2=0.01261467889908257,\n",
      " test_avg_error_2=0.014 \n",
      " 248 distinct classifiers:\n",
      "w=array([0., 0., 0., 0., 0.]), c=1 \\\\ \n",
      "w=array([-0.0020421, -0.0012436, -0.0042171, -0.0009043, -0.001    ]), c=1 \\\\ \n",
      "w=array([-0.003279 , -0.0029342, -0.0016991, -0.0003879,  0.       ]), c=2 \\\\ \n",
      "w=array([-0.0023119,  0.0009084, -0.0066305, -0.0045202,  0.001    ]), c=2 \\\\ \n",
      "w=array([-0.0038299, -0.0047862, -0.0067253, -0.0044935,  0.       ]), c=2 \\\\ \n",
      "w=array([-0.0044876, -0.007588 , -0.0030138, -0.0034961,  0.001    ]), c=5 \\\\ \n",
      "w=array([-0.0057543, -0.0047697, -0.0054398, -0.0053823,  0.002    ]), c=1 \\\\ \n",
      "w=array([-0.0052363, -0.0045111, -0.0062807, -0.0044211,  0.003    ]), c=6 \\\\ \n",
      "w=array([-0.0068392, -0.0049001, -0.0046607, -0.0025108,  0.004    ]), c=25 \\\\ \n",
      "w=array([-0.0052582, -0.004031 , -0.0069745, -0.0016867,  0.005    ]), c=10 \\\\ \n",
      "w=array([-0.0075199, -0.0087738, -0.0006256, -0.0015751,  0.006    ]), c=5 \\\\ \n",
      "w=array([-0.0070462, -0.0054133, -0.005132 , -0.0056182,  0.007    ]), c=27 \\\\ \n",
      "w=array([-0.0050152, -0.0035613, -0.0081441, -0.0056152,  0.008    ]), c=1 \\\\ \n",
      "w=array([-0.0067631, -0.0093843, -0.0022742, -0.0044032,  0.009    ]), c=3 \\\\ \n",
      "w=array([-0.0071828, -0.0064749, -0.0040601, -0.0066101,  0.01     ]), c=14 \\\\ \n",
      "w=array([-0.0097331, -0.0015231, -0.010433 , -0.0061941,  0.009    ]), c=1 \\\\ \n",
      "w=array([-0.0089888, -0.0052954, -0.0088199, -0.0046187,  0.01     ]), c=15 \\\\ \n",
      "w=array([-0.0082019, -0.0148617, -0.0050332,  0.0028847,  0.009    ]), c=1 \\\\ \n",
      "w=array([-0.009296 , -0.0125545, -0.0075569,  0.0014394,  0.01     ]), c=3 \\\\ \n",
      "w=array([-0.0090272, -0.0075675, -0.0127077, -0.0049519,  0.011    ]), c=13 \\\\ \n",
      "w=array([-0.0126284, -0.0141064, -0.0021843, -0.0054416,  0.012    ]), c=7 \\\\ \n",
      "w=array([-0.0161104, -0.009943 , -0.0056851, -0.0053631,  0.011    ]), c=3 \\\\ \n",
      "w=array([-0.01452  , -0.0077309, -0.0088034, -0.0054804,  0.012    ]), c=23 \\\\ \n",
      "w=array([-0.0150395, -0.0044676, -0.0118929, -0.0044955,  0.011    ]), c=7 \\\\ \n",
      "w=array([-0.0168582, -0.0135042, -0.0028767, -0.0046179,  0.012    ]), c=5 \\\\ \n",
      "w=array([-0.021198 , -0.0082006, -0.006757 , -0.0039136,  0.011    ]), c=14 \\\\ \n",
      "w=array([-0.0204111, -0.0177669, -0.0029703,  0.0035898,  0.01     ]), c=6 \\\\ \n",
      "w=array([-0.0206586, -0.0158301, -0.00544  ,  0.0027846,  0.011    ]), c=5 \\\\ \n",
      "w=array([-0.0211781, -0.0125668, -0.0085295,  0.0037695,  0.01     ]), c=8 \\\\ \n",
      "w=array([-0.0201229, -0.0113811, -0.0111706,  0.0038799,  0.011    ]), c=1 \\\\ \n",
      "w=array([-0.0181052, -0.0095829, -0.0141287,  0.0040898,  0.012    ]), c=7 \\\\ \n",
      "w=array([-0.022127 , -0.0178869, -0.0015737,  0.0025799,  0.013    ]), c=4 \\\\ \n",
      "w=array([-0.0219659, -0.0114245, -0.009931 ,  0.0041015,  0.012    ]), c=8 \\\\ \n",
      "w=array([-0.0216707, -0.0065389, -0.01508  , -0.0021308,  0.013    ]), c=2 \\\\ \n",
      "w=array([-0.0226561, -0.0131999, -0.0092555, -0.0015847,  0.014    ]), c=9 \\\\ \n",
      "w=array([-0.0215924, -0.0095042, -0.0134149, -0.0035226,  0.015    ]), c=4 \\\\ \n",
      "w=array([-0.0253427, -0.0229628,  0.0041783, -0.0062997,  0.016    ]), c=7 \\\\ \n",
      "w=array([-0.0264229, -0.0207632,  0.0015921, -0.0075756,  0.017    ]), c=4 \\\\ \n",
      "w=array([-0.0258835, -0.0168688, -0.0032245, -0.0119174,  0.018    ]), c=2 \\\\ \n",
      "w=array([-0.0276255, -0.0120598, -0.0114387, -0.0098515,  0.017    ]), c=31 \\\\ \n",
      "w=array([-0.0261754, -0.0084531, -0.0154944, -0.0114481,  0.018    ]), c=8 \\\\ \n",
      "w=array([-0.0263662, -0.0175828, -0.0117694, -0.0056257,  0.017    ]), c=4 \\\\ \n",
      "w=array([-0.0253545, -0.0166806, -0.01412  , -0.0051986,  0.018    ]), c=43 \\\\ \n",
      "w=array([-0.0229628, -0.0121241, -0.0191088, -0.0080973,  0.019    ]), c=13 \\\\ \n",
      "w=array([-0.0276959, -0.018303 , -0.0077208, -0.0091714,  0.02     ]), c=8 \\\\ \n",
      "w=array([-0.0280252, -0.0138478, -0.0122926, -0.0081826,  0.019    ]), c=114 \\\\ \n",
      "w=array([-0.0262921, -0.0098934, -0.0170338, -0.0106843,  0.02     ]), c=50 \\\\ \n",
      "w=array([-0.0282987, -0.0166124, -0.0080176, -0.0105843,  0.021    ]), c=12 \\\\ \n",
      "w=array([-0.0286279, -0.0121572, -0.0125894, -0.0095955,  0.02     ]), c=47 \\\\ \n",
      "w=array([-0.025929 , -0.0243556, -0.013266 , -0.0010473,  0.019    ]), c=9 \\\\ \n",
      "w=array([-0.0258131, -0.0211337, -0.0166962, -0.003893 ,  0.02     ]), c=30 \\\\ \n",
      "w=array([-0.0263325, -0.0178704, -0.0197857, -0.0029081,  0.019    ]), c=28 \\\\ \n",
      "w=array([-0.0246526, -0.0136636, -0.0243255, -0.0053012,  0.02     ]), c=4 \\\\ \n",
      "w=array([-0.0220047, -0.023801 , -0.0229945,  0.0001695,  0.019    ]), c=32 \\\\ \n",
      "w=array([-0.0271708, -0.0157577, -0.0229502, -0.0043288,  0.02     ]), c=62 \\\\ \n",
      "w=array([-0.0316483, -0.028788 , -0.0058668, -0.0073633,  0.021    ]), c=1 \\\\ \n",
      "w=array([-0.031538 , -0.0268139, -0.0092336, -0.0080159,  0.022    ]), c=2 \\\\ \n",
      "w=array([-0.0312647, -0.0219366, -0.014153 , -0.0138357,  0.023    ]), c=76 \\\\ \n",
      "w=array([-0.0300449, -0.0198384, -0.0173484, -0.0137073,  0.024    ]), c=32 \\\\ \n",
      "w=array([-0.0278506, -0.0152881, -0.0223244, -0.0164327,  0.025    ]), c=10 \\\\ \n",
      "w=array([-0.0285083, -0.0180899, -0.0186129, -0.0154353,  0.026    ]), c=37 \\\\ \n",
      "w=array([-0.0269273, -0.0172208, -0.0209267, -0.0146112,  0.027    ]), c=11 \\\\ \n",
      "w=array([-0.0242794, -0.0273582, -0.0195957, -0.0091405,  0.026    ]), c=31 \\\\ \n",
      "w=array([-0.0222484, -0.0255062, -0.0226078, -0.0091375,  0.027    ]), c=16 \\\\ \n",
      "w=array([-0.0292905, -0.0163062, -0.0223485, -0.0138207,  0.028    ]), c=18 \\\\ \n",
      "w=array([-0.0285036, -0.0258725, -0.0185618, -0.0063173,  0.027    ]), c=27 \\\\ \n",
      "w=array([-0.0269132, -0.0236604, -0.0216801, -0.0064345,  0.028    ]), c=23 \\\\ \n",
      "w=array([-0.0274327, -0.0203971, -0.0247696, -0.0054496,  0.027    ]), c=37 \\\\ \n",
      "w=array([-0.0279522, -0.0171338, -0.0278591, -0.0044647,  0.026    ]), c=6 \\\\ \n",
      "w=array([-0.0297598, -0.0259469, -0.0191505, -0.0046815,  0.027    ]), c=3 \\\\ \n",
      "w=array([-0.0277421, -0.0241487, -0.0221086, -0.0044716,  0.028    ]), c=11 \\\\ \n",
      "w=array([-0.027581 , -0.0176863, -0.0304659, -0.00295  ,  0.027    ]), c=10 \\\\ \n",
      "w=array([-0.0285664, -0.0243473, -0.0246414, -0.0024039,  0.028    ]), c=53 \\\\ \n",
      "w=array([-0.0349028, -0.0150625, -0.0246271, -0.0091883,  0.029    ]), c=12 \\\\ \n",
      "w=array([-0.0350936, -0.0241922, -0.0209021, -0.0033659,  0.028    ]), c=47 \\\\ \n",
      "w=array([-0.0327019, -0.0196357, -0.0258909, -0.0062646,  0.029    ]), c=40 \\\\ \n",
      "w=array([-0.0363004, -0.033295 , -0.0082857, -0.0087573,  0.03     ]), c=13 \\\\ \n",
      "w=array([-0.0383055, -0.0264312, -0.0164177, -0.0085172,  0.029    ]), c=82 \\\\ \n",
      "w=array([-0.0365724, -0.0224768, -0.0211589, -0.0110189,  0.03     ]), c=2 \\\\ \n",
      "w=array([-0.0350647, -0.0205172, -0.0242173, -0.0111414,  0.031    ]), c=60 \\\\ \n",
      "w=array([-0.0353939, -0.016062 , -0.0287891, -0.0101526,  0.03     ]), c=19 \\\\ \n",
      "w=array([-0.0384805, -0.0226982, -0.0182486, -0.0110444,  0.031    ]), c=67 \\\\ \n",
      "w=array([-0.039    , -0.0194349, -0.0213381, -0.0100595,  0.03     ]), c=32 \\\\ \n",
      "w=array([-0.0363521, -0.0295723, -0.0200071, -0.0045888,  0.029    ]), c=5 \\\\ \n",
      "w=array([-0.0356703, -0.0247219, -0.0252204, -0.0106931,  0.03     ]), c=200 \\\\ \n",
      "w=array([-0.033476 , -0.0201716, -0.0301964, -0.0134185,  0.031    ]), c=10 \\\\ \n",
      "w=array([-0.0341337, -0.0229734, -0.0264849, -0.0124211,  0.032    ]), c=79 \\\\ \n",
      "w=array([-0.0321027, -0.0211214, -0.029497 , -0.0124181,  0.033    ]), c=34 \\\\ \n",
      "w=array([-0.0313158, -0.0306877, -0.0257103, -0.0049147,  0.032    ]), c=27 \\\\ \n",
      "w=array([-0.0297254, -0.0284756, -0.0288286, -0.0050319,  0.033    ]), c=7 \\\\ \n",
      "w=array([-0.0337188, -0.0226423, -0.0282814, -0.0099698,  0.034    ]), c=16 \\\\ \n",
      "w=array([-0.0342383, -0.019379 , -0.0313709, -0.0089849,  0.033    ]), c=7 \\\\ \n",
      "w=array([-0.036057 , -0.0284156, -0.0223547, -0.0091074,  0.034    ]), c=30 \\\\ \n",
      "w=array([-0.0365765, -0.0251523, -0.0254442, -0.0081225,  0.033    ]), c=9 \\\\ \n",
      "w=array([-0.0345588, -0.0233541, -0.0284023, -0.0079126,  0.034    ]), c=82 \\\\ \n",
      "w=array([-0.0350783, -0.0200908, -0.0314918, -0.0069276,  0.033    ]), c=4 \\\\ \n",
      "w=array([-0.0352691, -0.0292205, -0.0277668, -0.0011052,  0.032    ]), c=47 \\\\ \n",
      "w=array([-0.0328774, -0.024664 , -0.0327556, -0.0040039,  0.033    ]), c=13 \\\\ \n",
      "w=array([-0.0376105, -0.0308429, -0.0213676, -0.005078 ,  0.034    ]), c=8 \\\\ \n",
      "w=array([-0.0379397, -0.0263877, -0.0259394, -0.0040892,  0.033    ]), c=114 \\\\ \n",
      "w=array([-0.0362066, -0.0224333, -0.0306806, -0.0065909,  0.034    ]), c=50 \\\\ \n",
      "w=array([-0.0382132, -0.0291523, -0.0216644, -0.006491 ,  0.035    ]), c=12 \\\\ \n",
      "w=array([-0.0385424, -0.0246971, -0.0262362, -0.0055022,  0.034    ]), c=86 \\\\ \n",
      "w=array([-0.0390619, -0.0214338, -0.0293257, -0.0045173,  0.033    ]), c=126 \\\\ \n",
      "w=array([-0.0435394, -0.0344641, -0.0122423, -0.0075518,  0.034    ]), c=3 \\\\ \n",
      "w=array([-0.0432661, -0.0295868, -0.0171617, -0.0133716,  0.035    ]), c=51 \\\\ \n",
      "w=array([-0.0420382, -0.0255559, -0.0218052, -0.0172841,  0.036    ]), c=25 \\\\ \n",
      "w=array([-0.0408184, -0.0234577, -0.0250006, -0.0171556,  0.037    ]), c=14 \\\\ \n",
      "w=array([-0.0395184, -0.0337255, -0.0220476, -0.0112918,  0.036    ]), c=18 \\\\ \n",
      "w=array([-0.0373241, -0.0291752, -0.0270236, -0.0140172,  0.037    ]), c=89 \\\\ \n",
      "w=array([-0.0352931, -0.0273232, -0.0300357, -0.0140142,  0.038    ]), c=34 \\\\ \n",
      "w=array([-0.0345062, -0.0368895, -0.026249 , -0.0065108,  0.037    ]), c=27 \\\\ \n",
      "w=array([-0.0329158, -0.0346774, -0.0293673, -0.0066281,  0.038    ]), c=7 \\\\ \n",
      "w=array([-0.0369092, -0.0288441, -0.02882  , -0.011566 ,  0.039    ]), c=16 \\\\ \n",
      "w=array([-0.0374287, -0.0255808, -0.0319095, -0.0105811,  0.038    ]), c=26 \\\\ \n",
      "w=array([-0.0366418, -0.0351471, -0.0281228, -0.0030777,  0.037    ]), c=11 \\\\ \n",
      "w=array([-0.0371613, -0.0318838, -0.0312123, -0.0020928,  0.036    ]), c=9 \\\\ \n",
      "w=array([-0.0351436, -0.0300856, -0.0341704, -0.0018829,  0.037    ]), c=34 \\\\ \n",
      "w=array([-0.0388939, -0.0435442, -0.0165772, -0.00466  ,  0.038    ]), c=11 \\\\ \n",
      "w=array([-0.0383545, -0.0396498, -0.0213938, -0.0090018,  0.039    ]), c=2 \\\\ \n",
      "w=array([-0.0400965, -0.0348408, -0.029608 , -0.0069359,  0.038    ]), c=31 \\\\ \n",
      "w=array([-0.0386464, -0.0312341, -0.0336637, -0.0085325,  0.039    ]), c=4 \\\\ \n",
      "w=array([-0.0391659, -0.0279708, -0.0367532, -0.0075476,  0.038    ]), c=64 \\\\ \n",
      "w=array([-0.043899 , -0.0341497, -0.0253652, -0.0086217,  0.039    ]), c=8 \\\\ \n",
      "w=array([-0.0442282, -0.0296945, -0.029937 , -0.0076329,  0.038    ]), c=176 \\\\ \n",
      "w=array([-0.0445574, -0.0252393, -0.0345088, -0.0066441,  0.037    ]), c=19 \\\\ \n",
      "w=array([-0.047644 , -0.0318755, -0.0239683, -0.0075359,  0.038    ]), c=67 \\\\ \n",
      "w=array([-0.0481635, -0.0286122, -0.0270578, -0.006551 ,  0.037    ]), c=28 \\\\ \n",
      "w=array([-0.0464836, -0.0244054, -0.0315976, -0.0089441,  0.038    ]), c=4 \\\\ \n",
      "w=array([-0.0438357, -0.0345428, -0.0302666, -0.0034734,  0.037    ]), c=32 \\\\ \n",
      "w=array([-0.0490018, -0.0264995, -0.0302224, -0.0079717,  0.038    ]), c=173 \\\\ \n",
      "w=array([-0.0468075, -0.0219492, -0.0351984, -0.0106971,  0.039    ]), c=10 \\\\ \n",
      "w=array([-0.0474652, -0.024751 , -0.0314869, -0.0096997,  0.04     ]), c=48 \\\\ \n",
      "w=array([-0.0448173, -0.0348884, -0.0301559, -0.004229 ,  0.039    ]), c=31 \\\\ \n",
      "w=array([-0.0427863, -0.0330364, -0.033168 , -0.004226 ,  0.04     ]), c=84 \\\\ \n",
      "w=array([-0.0433058, -0.0297731, -0.0362575, -0.0032411,  0.039    ]), c=37 \\\\ \n",
      "w=array([-0.0438253, -0.0265098, -0.039347 , -0.0022562,  0.038    ]), c=16 \\\\ \n",
      "w=array([-0.0478471, -0.0348138, -0.026792 , -0.0037661,  0.039    ]), c=4 \\\\ \n",
      "w=array([-0.047686 , -0.0283514, -0.0351493, -0.0022445,  0.038    ]), c=23 \\\\ \n",
      "w=array([-0.0514363, -0.04181  , -0.0175561, -0.0050216,  0.039    ]), c=11 \\\\ \n",
      "w=array([-0.050897 , -0.0379156, -0.0223727, -0.0093634,  0.04     ]), c=3 \\\\ \n",
      "w=array([-0.0518267, -0.0341185, -0.0270156, -0.0090677,  0.039    ]), c=30 \\\\ \n",
      "w=array([-0.0503766, -0.0305118, -0.0310713, -0.0106643,  0.04     ]), c=4 \\\\ \n",
      "w=array([-0.050896 , -0.0272485, -0.0341608, -0.0096794,  0.039    ]), c=51 \\\\ \n",
      "w=array([-0.0485043, -0.022692 , -0.0391496, -0.0125781,  0.04     ]), c=13 \\\\ \n",
      "w=array([-0.0532374, -0.0288709, -0.0277616, -0.0136522,  0.041    ]), c=8 \\\\ \n",
      "w=array([-0.0535667, -0.0244157, -0.0323334, -0.0126634,  0.04     ]), c=94 \\\\ \n",
      "w=array([-0.0522667, -0.0346835, -0.0293804, -0.0067996,  0.039    ]), c=20 \\\\ \n",
      "w=array([-0.0505336, -0.0307291, -0.0341216, -0.0093013,  0.04     ]), c=62 \\\\ \n",
      "w=array([-0.0508628, -0.0262739, -0.0386934, -0.0083125,  0.039    ]), c=19 \\\\ \n",
      "w=array([-0.0539494, -0.0329101, -0.0281529, -0.0092043,  0.04     ]), c=67 \\\\ \n",
      "w=array([-0.0544689, -0.0296468, -0.0312424, -0.0082194,  0.039    ]), c=28 \\\\ \n",
      "w=array([-0.052789 , -0.02544  , -0.0357822, -0.0106125,  0.04     ]), c=4 \\\\ \n",
      "w=array([-0.0501411, -0.0355774, -0.0344512, -0.0051418,  0.039    ]), c=205 \\\\ \n",
      "w=array([-0.0479468, -0.0310271, -0.0394272, -0.0078672,  0.04     ]), c=37 \\\\ \n",
      "w=array([-0.0511773, -0.0382406, -0.0277839, -0.0088133,  0.041    ]), c=1 \\\\ \n",
      "w=array([-0.0499693, -0.0341662, -0.0325474, -0.0114262,  0.042    ]), c=7 \\\\ \n",
      "w=array([-0.0481818, -0.0293862, -0.0376836, -0.0146624,  0.043    ]), c=13 \\\\ \n",
      "w=array([-0.0455339, -0.0395236, -0.0363526, -0.0091917,  0.042    ]), c=31 \\\\ \n",
      "w=array([-0.0435029, -0.0376716, -0.0393647, -0.0091887,  0.043    ]), c=84 \\\\ \n",
      "w=array([-0.0440224, -0.0344083, -0.0424542, -0.0082038,  0.042    ]), c=37 \\\\ \n",
      "w=array([-0.0445419, -0.031145 , -0.0455437, -0.0072189,  0.041    ]), c=16 \\\\ \n",
      "w=array([-0.0485637, -0.039449 , -0.0329887, -0.0087288,  0.042    ]), c=4 \\\\ \n",
      "w=array([-0.0484026, -0.0329866, -0.041346 , -0.0072072,  0.041    ]), c=23 \\\\ \n",
      "w=array([-0.0521529, -0.0464452, -0.0237528, -0.0099843,  0.042    ]), c=11 \\\\ \n",
      "w=array([-0.0516135, -0.0425508, -0.0285694, -0.0143261,  0.043    ]), c=3 \\\\ \n",
      "w=array([-0.0525432, -0.0387537, -0.0332123, -0.0140304,  0.042    ]), c=30 \\\\ \n",
      "w=array([-0.0510931, -0.035147 , -0.037268 , -0.015627 ,  0.043    ]), c=4 \\\\ \n",
      "w=array([-0.0516126, -0.0318837, -0.0403575, -0.0146421,  0.042    ]), c=91 \\\\ \n",
      "w=array([-0.0552111, -0.045543 , -0.0227523, -0.0171348,  0.043    ]), c=13 \\\\ \n",
      "w=array([-0.0572162, -0.0386792, -0.0308843, -0.0168947,  0.042    ]), c=82 \\\\ \n",
      "w=array([-0.0554831, -0.0347248, -0.0356255, -0.0193964,  0.043    ]), c=62 \\\\ \n",
      "w=array([-0.0558123, -0.0302696, -0.0401973, -0.0184076,  0.042    ]), c=61 \\\\ \n",
      "w=array([-0.0531644, -0.040407 , -0.0388663, -0.0129369,  0.041    ]), c=25 \\\\ \n",
      "w=array([-0.0536839, -0.0371437, -0.0419558, -0.011952 ,  0.04     ]), c=237 \\\\ \n",
      "w=array([-0.0514896, -0.0325934, -0.0469318, -0.0146774,  0.041    ]), c=10 \\\\ \n",
      "w=array([-0.0521473, -0.0353952, -0.0432203, -0.01368  ,  0.042    ]), c=27 \\\\ \n",
      "w=array([-0.0553778, -0.0426087, -0.031577 , -0.0146261,  0.043    ]), c=1 \\\\ \n",
      "w=array([-0.0541698, -0.0385343, -0.0363405, -0.017239 ,  0.044    ]), c=9 \\\\ \n",
      "w=array([-0.0525888, -0.0376652, -0.0386543, -0.0164149,  0.045    ]), c=42 \\\\ \n",
      "w=array([-0.0505578, -0.0358132, -0.0416664, -0.0164119,  0.046    ]), c=34 \\\\ \n",
      "w=array([-0.0497709, -0.0453795, -0.0378797, -0.0089085,  0.045    ]), c=27 \\\\ \n",
      "w=array([-0.0481805, -0.0431674, -0.040998 , -0.0090258,  0.046    ]), c=23 \\\\ \n",
      "w=array([-0.0487   , -0.0399041, -0.0440875, -0.0080409,  0.045    ]), c=37 \\\\ \n",
      "w=array([-0.0492195, -0.0366408, -0.047177 , -0.007056 ,  0.044    ]), c=16 \\\\ \n",
      "w=array([-0.0532413, -0.0449448, -0.034622 , -0.0085659,  0.045    ]), c=4 \\\\ \n",
      "w=array([-0.0530802, -0.0384824, -0.0429793, -0.0070443,  0.044    ]), c=71 \\\\ \n",
      "w=array([-0.0535997, -0.0352191, -0.0460688, -0.0060593,  0.043    ]), c=64 \\\\ \n",
      "w=array([-0.0583328, -0.041398 , -0.0346808, -0.0071334,  0.044    ]), c=8 \\\\ \n",
      "w=array([-0.058662 , -0.0369428, -0.0392526, -0.0061446,  0.043    ]), c=114 \\\\ \n",
      "w=array([-0.0569289, -0.0329884, -0.0439938, -0.0086463,  0.044    ]), c=50 \\\\ \n",
      "w=array([-0.0589355, -0.0397074, -0.0349776, -0.0085464,  0.045    ]), c=12 \\\\ \n",
      "w=array([-0.0592647, -0.0352522, -0.0395494, -0.0075576,  0.044    ]), c=86 \\\\ \n",
      "w=array([-0.0597842, -0.0319889, -0.0426389, -0.0065727,  0.043    ]), c=167 \\\\ \n",
      "w=array([-0.0634803, -0.0456668, -0.0250594, -0.0091908,  0.044    ]), c=13 \\\\ \n",
      "w=array([-0.0622524, -0.0416359, -0.0297029, -0.0131033,  0.045    ]), c=14 \\\\ \n",
      "w=array([-0.0609952, -0.0367628, -0.034989 , -0.0189774,  0.046    ]), c=43 \\\\ \n",
      "w=array([-0.0588009, -0.0322125, -0.039965 , -0.0217028,  0.047    ]), c=58 \\\\ \n",
      "w=array([-0.056153 , -0.0423499, -0.038634 , -0.0162321,  0.046    ]), c=31 \\\\ \n",
      "w=array([-0.054122 , -0.0404979, -0.0416461, -0.0162291,  0.047    ]), c=84 \\\\ \n",
      "w=array([-0.0546415, -0.0372346, -0.0447356, -0.0152442,  0.046    ]), c=26 \\\\ \n",
      "w=array([-0.0538546, -0.0468009, -0.0409489, -0.0077408,  0.045    ]), c=11 \\\\ \n",
      "w=array([-0.0543741, -0.0435376, -0.0440384, -0.0067559,  0.044    ]), c=9 \\\\ \n",
      "w=array([-0.0523564, -0.0417394, -0.0469965, -0.006546 ,  0.045    ]), c=34 \\\\ \n",
      "w=array([-0.0561067, -0.055198 , -0.0294033, -0.0093231,  0.046    ]), c=11 \\\\ \n",
      "w=array([-0.0555674, -0.0513036, -0.0342199, -0.0136649,  0.047    ]), c=3 \\\\ \n",
      "w=array([-0.0564971, -0.0475065, -0.0388628, -0.0133692,  0.046    ]), c=30 \\\\ \n",
      "w=array([-0.055047 , -0.0438998, -0.0429185, -0.0149658,  0.047    ]), c=4 \\\\ \n",
      "w=array([-0.0555664, -0.0406365, -0.046008 , -0.0139808,  0.046    ]), c=51 \\\\ \n",
      "w=array([-0.0531747, -0.03608  , -0.0509968, -0.0168795,  0.047    ]), c=13 \\\\ \n",
      "w=array([-0.0579078, -0.0422589, -0.0396088, -0.0179536,  0.048    ]), c=8 \\\\ \n",
      "w=array([-0.0582371, -0.0378037, -0.0441806, -0.0169648,  0.047    ]), c=176 \\\\ \n",
      "w=array([-0.0585663, -0.0333485, -0.0487524, -0.015976 ,  0.046    ]), c=19 \\\\ \n",
      "w=array([-0.0616529, -0.0399847, -0.0382119, -0.0168679,  0.047    ]), c=67 \\\\ \n",
      "w=array([-0.0621724, -0.0367214, -0.0413014, -0.015883 ,  0.046    ]), c=237 \\\\ \n",
      "w=array([-0.0599781, -0.0321711, -0.0462774, -0.0186084,  0.047    ]), c=10 \\\\ \n",
      "w=array([-0.0606357, -0.0349729, -0.0425659, -0.017611 ,  0.048    ]), c=48 \\\\ \n",
      "w=array([-0.0579878, -0.0451103, -0.0412349, -0.0121403,  0.047    ]), c=31 \\\\ \n",
      "w=array([-0.0559568, -0.0432583, -0.044247 , -0.0121373,  0.048    ]), c=84 \\\\ \n",
      "w=array([-0.0564763, -0.039995 , -0.0473365, -0.0111524,  0.047    ]), c=37 \\\\ \n",
      "w=array([-0.0569958, -0.0367317, -0.050426 , -0.0101675,  0.046    ]), c=16 \\\\ \n",
      "w=array([-0.0610176, -0.0450357, -0.037871 , -0.0116774,  0.047    ]), c=4 \\\\ \n",
      "w=array([-0.0608566, -0.0385733, -0.0462283, -0.0101558,  0.046    ]), c=71 \\\\ \n",
      "w=array([-0.061376 , -0.03531  , -0.0493178, -0.0091708,  0.045    ]), c=91 \\\\ \n",
      "w=array([-0.0649745, -0.0489693, -0.0317126, -0.0116635,  0.046    ]), c=95 \\\\ \n",
      "w=array([-0.0632414, -0.0450149, -0.0364538, -0.0141652,  0.047    ]), c=2 \\\\ \n",
      "w=array([-0.0617337, -0.0430553, -0.0395122, -0.0142877,  0.048    ]), c=60 \\\\ \n",
      "w=array([-0.0620629, -0.0386001, -0.044084 , -0.0132989,  0.047    ]), c=86 \\\\ \n",
      "w=array([-0.0625824, -0.0353368, -0.0471735, -0.012314 ,  0.046    ]), c=167 \\\\ \n",
      "w=array([-0.0662785, -0.0490147, -0.029594 , -0.0149321,  0.047    ]), c=13 \\\\ \n",
      "w=array([-0.0650506, -0.0449838, -0.0342375, -0.0188446,  0.048    ]), c=25 \\\\ \n",
      "w=array([-0.0638308, -0.0428856, -0.0374329, -0.0187161,  0.049    ]), c=32 \\\\ \n",
      "w=array([-0.0616365, -0.0383353, -0.0424089, -0.0214415,  0.05     ]), c=47 \\\\ \n",
      "w=array([-0.0600555, -0.0374662, -0.0447227, -0.0206174,  0.051    ]), c=11 \\\\ \n",
      "w=array([-0.0574076, -0.0476036, -0.0433917, -0.0151467,  0.05     ]), c=31 \\\\ \n",
      "w=array([-0.0553766, -0.0457516, -0.0464038, -0.0151437,  0.051    ]), c=84 \\\\ \n",
      "w=array([-0.0558961, -0.0424883, -0.0494933, -0.0141588,  0.05     ]), c=37 \\\\ \n",
      "w=array([-0.0564156, -0.039225 , -0.0525828, -0.0131739,  0.049    ]), c=16 \\\\ \n",
      "w=array([-0.0604374, -0.047529 , -0.0400278, -0.0146838,  0.05     ]), c=4 \\\\ \n",
      "w=array([-0.0602763, -0.0410666, -0.0483851, -0.0131622,  0.049    ]), c=71 \\\\ \n",
      "w=array([-0.0607958, -0.0378033, -0.0514746, -0.0121773,  0.048    ]), c=64 \\\\ \n",
      "w=array([-0.0655289, -0.0439822, -0.0400866, -0.0132514,  0.049    ]), c=8 \\\\ \n",
      "w=array([-0.0658582, -0.039527 , -0.0446584, -0.0122626,  0.048    ]), c=176 \\\\ \n",
      "w=array([-0.0661874, -0.0350718, -0.0492302, -0.0112738,  0.047    ]), c=19 \\\\ \n",
      "w=array([-0.069274 , -0.041708 , -0.0386897, -0.0121656,  0.048    ]), c=67 \\\\ \n",
      "w=array([-0.0697935, -0.0384447, -0.0417792, -0.0111807,  0.047    ]), c=28 \\\\ \n",
      "w=array([-0.0681136, -0.0342379, -0.046319 , -0.0135738,  0.048    ]), c=4 \\\\ \n",
      "w=array([-0.0654657, -0.0443753, -0.044988 , -0.0081031,  0.047    ]), c=205 \\\\ \n"
     ]
    }
   ],
   "source": [
    "train_preds_2 = voted_predict(x_train,keeps)\n",
    "train_avg_error_2 = calc_avg_error(train_preds_2,y_train)\n",
    "\n",
    "test_preds_2 = voted_predict(x_test,keeps)\n",
    "test_avg_error_2 = calc_avg_error(test_preds_2, y_test)\n",
    "\n",
    "print(f'VOTED PERCEPTRON \\n {train_avg_error_2=},\\n {test_avg_error_2=} \\n {len(keeps)} distinct classifiers:')\n",
    "for (w,c) in keeps:\n",
    "    print(f'{w=}, {c=} \\\\\\ ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dee4117-3ac8-48d0-a973-47c86873a288",
   "metadata": {},
   "source": [
    "### Averaged Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "9eafe97b-cbbf-48fd-a3ab-12b622a0d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### utilities\n",
    "calc_avg_error = lambda preds,labels: (preds != labels).mean()\n",
    "predict = lambda x,w: np.sign(x @ w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "00d311c8-f9d7-4e6f-a23a-f89fe2da8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize w\n",
    "w_3 = np.zeros((x_train.shape[1],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "c4f1f6a2-8542-420d-b0d7-6564fbfa4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 10\n",
    "a = np.zeros_like(w_3)\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(x_train.shape[0]):\n",
    "        \n",
    "        pred = predict(x_train[i], w_3)\n",
    "        label = y_train[i]\n",
    "        if pred != label:\n",
    "            # if we guess negative but answer is positive, increase\n",
    "            if pred == -1:\n",
    "                w_3 += lr * x_train[i]\n",
    "            # if we guess positive but answer is negative, decrease\n",
    "            else:\n",
    "                w_3 -= lr * x_train[i]\n",
    "        a = a + w_3\n",
    "        \n",
    "# a = a / (num_epochs * x_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "1009134f-bdfa-4594-b7cd-7e773c888d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERGAGED PERCEPTRON \n",
      " w_3=array([-0.0632714, -0.039825 , -0.049964 , -0.0108285,  0.048    ])\n",
      " a=array([-415.2778658, -275.0157039, -291.366328 ,  -88.4358621,\n",
      "        334.232    ])\n",
      " train_avg_error_3=0.01261467889908257,\n",
      " test_avg_error_3=0.014\n"
     ]
    }
   ],
   "source": [
    "train_preds_3 = predict(x_train,a)\n",
    "train_avg_error_3 = calc_avg_error(train_preds_3,y_train)\n",
    "\n",
    "test_preds_3 = predict(x_test,a)\n",
    "test_avg_error_3 = calc_avg_error(test_preds_3, y_test)\n",
    "\n",
    "print(f'AVERGAGED PERCEPTRON \\n {w_3=}\\n {a=}\\n {train_avg_error_3=},\\n {test_avg_error_3=}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0ab04d-68f1-48b3-9bed-bafe9f801fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt",
   "language": "python",
   "name": "opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
