{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55da1056-1585-4f5c-ad69-f279523e9f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_fns import (adaboost,\n",
    "                          adaboost_pred,\n",
    "                          adaboost_acc,\n",
    "                          random_forest, \n",
    "                          bagging, \n",
    "                          forest_pred,\n",
    "                          forest_acc)\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from datasets import get_bank_data\n",
    "from decision_tree_fns import predict, tree_maker, ID3\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40788d50-1cbf-4776-82d9-53fc20f6edae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default of credit card clients.xls']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../datasets/credit_card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60de9bc9-e7d1-44a4-8963-1ead9e00f8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlrd\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xlrd\n",
      "Successfully installed xlrd-2.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install xlrd ## for pd.read_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff9700c-567e-4cb2-ba89-efd5b21e43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fp = os.path.join('../datasets/credit_card',os.listdir('../datasets/credit_card')[0])\n",
    "df = pd.read_excel(dataset_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef060ad-c2b3-4765-b9b7-4cabd2a2dcfb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preview df       Unnamed: 0         X1   X2         X3        X4   X5     X6     X7  \\\n",
      "0             ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2   \n",
      "1              1      20000    2          2         1   24      2      2   \n",
      "2              2     120000    2          2         2   26     -1      2   \n",
      "3              3      90000    2          2         2   34      0      0   \n",
      "4              4      50000    2          2         1   37      0      0   \n",
      "...          ...        ...  ...        ...       ...  ...    ...    ...   \n",
      "29996      29996     220000    1          3         1   39      0      0   \n",
      "29997      29997     150000    1          3         2   43     -1     -1   \n",
      "29998      29998      30000    1          2         2   37      4      3   \n",
      "29999      29999      80000    1          3         1   41      1     -1   \n",
      "30000      30000      50000    1          2         1   46      0      0   \n",
      "\n",
      "          X8     X9  ...        X15        X16        X17       X18       X19  \\\n",
      "0      PAY_3  PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2   \n",
      "1         -1     -1  ...          0          0          0         0       689   \n",
      "2          0      0  ...       3272       3455       3261         0      1000   \n",
      "3          0      0  ...      14331      14948      15549      1518      1500   \n",
      "4          0      0  ...      28314      28959      29547      2000      2019   \n",
      "...      ...    ...  ...        ...        ...        ...       ...       ...   \n",
      "29996      0      0  ...      88004      31237      15980      8500     20000   \n",
      "29997     -1     -1  ...       8979       5190          0      1837      3526   \n",
      "29998      2     -1  ...      20878      20582      19357         0         0   \n",
      "29999      0      0  ...      52774      11855      48944     85900      3409   \n",
      "30000      0      0  ...      36535      32428      15313      2078      1800   \n",
      "\n",
      "            X20       X21       X22       X23                           Y  \n",
      "0      PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
      "1             0         0         0         0                           1  \n",
      "2          1000      1000         0      2000                           1  \n",
      "3          1000      1000      1000      5000                           0  \n",
      "4          1200      1100      1069      1000                           0  \n",
      "...         ...       ...       ...       ...                         ...  \n",
      "29996      5003      3047      5000      1000                           0  \n",
      "29997      8998       129         0         0                           0  \n",
      "29998     22000      4200      2000      3100                           1  \n",
      "29999      1178      1926     52964      1804                           1  \n",
      "30000      1430      1000      1000      1000                           1  \n",
      "\n",
      "[30001 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print('preview df', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "800672a4-7e5a-44ec-b8de-5ae2bf50d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.to_numpy()\n",
    "X = dataset[1:,1:-1] #all rows except first, all cols except first or last\n",
    "y = dataset[1:,-1]   #all rows except first, only last column\n",
    "feat_names = dataset[0,1:-1]  #first row is headers, include all columns except first/last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d19838-c314-43f2-8c33-570142a9a24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded credit card data from xls file y.shape=(30000,) (30000, 23), feat_names.shape=(23,)\n"
     ]
    }
   ],
   "source": [
    "print(f'loaded credit card data from xls file {y.shape=} {X.shape}, {feat_names.shape=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6254560d-18fc-4418-b002-ed1384cdcc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "\n",
    "shuffle = np.random.choice(len(X), 30000, replace=False)\n",
    "split = 24000\n",
    "\n",
    "# be careful that columns of X_train might not have all the feature values that X_test does\n",
    "X,y = X[shuffle], y[shuffle]\n",
    "X_train, y_train = X[:split], y[:split]\n",
    "X_test, y_test = X[split:], y[split:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8734d07-b792-4549-a8db-c235eb619460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split data, X_train.shape=(24000, 23), y_train.shape=(24000,), X_test.shape=(6000, 23), y_test.shape=(6000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'split data, {X_train.shape=}, {y_train.shape=}, {X_test.shape=}, {y_test.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4de8bd-b425-4851-a295-bb5d0ea84856",
   "metadata": {},
   "source": [
    "### handle continuous features using median splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d12843-10fb-4ecb-80d0-f39bc1649e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continous features are ['LIMIT_BAL' 'AGE' 'BILL_AMT1' 'BILL_AMT2' 'BILL_AMT3' 'BILL_AMT4'\n",
      " 'BILL_AMT5' 'BILL_AMT6' 'PAY_AMT1' 'PAY_AMT2' 'PAY_AMT3' 'PAY_AMT4'\n",
      " 'PAY_AMT5' 'PAY_AMT6']\n"
     ]
    }
   ],
   "source": [
    "# continuous features are limit bal [0], age [4], bill amt 1 [11], rest of features [12:]\n",
    "# [] denotes the column\n",
    "numeric_features = [0,4,11,12,13,14,15,16,17,18,19,20,21,22]\n",
    "print('continous features are', feat_names[numeric_features])\n",
    "\n",
    "medians = np.median(X_train[:, numeric_features], axis=0)\n",
    "X_train[:,numeric_features] = X_train[:,numeric_features] > medians\n",
    "X_test[:,numeric_features] = X_test[:,numeric_features] > medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf0d272-8570-45fa-8596-cd7132e116be",
   "metadata": {},
   "source": [
    "### single tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e1c9bdc-4f2f-48df-bc6e-2ead03c7ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_tree = ID3(X_train,y_train,feat_names, max_depth=100, IG_metric='entropy')\n",
    "\n",
    "with open(f'./3/single_tree.pkl','wb') as f:\n",
    "    pickle.dump(single_tree, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2d72368-eecd-4d5e-b57a-741c91daadd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single tree accuracies, 0.940375 train, 0.7555 test\n"
     ]
    }
   ],
   "source": [
    "tree_train_acc = (y_train == [predict(X_train[ex],single_tree,feat_names) for ex in range(len(X_train))]).mean()\n",
    "tree_test_acc = (y_test == [predict(X_test[ex],single_tree,feat_names) for ex in range(len(X_test))]).mean()\n",
    "\n",
    "print(f'single tree accuracies, {tree_train_acc} train, {tree_test_acc} test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ba4eb-3aba-4b95-93a8-fa1b4a9ee593",
   "metadata": {},
   "source": [
    "### adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "789e6bd7-8546-4ab7-9bb0-da4cb6414b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "stumps, amount_of_says = adaboost(X_train,\n",
    "                                  y_train,\n",
    "                                  feat_names, \n",
    "                                  num_stumps=500, \n",
    "                                  IG_metric='entropy')\n",
    "with open(f'./3/adaboost.pkl','wb') as f:\n",
    "    pickle.dump((stumps,amount_of_says), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46dc8eff-eddf-45f5-b799-de45c71a651c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaboost ensemble accuracies, 0.821625 train, 0.8115 test\n"
     ]
    }
   ],
   "source": [
    "ada_train_acc = adaboost_acc(X_train,y_train,stumps,feat_names, amount_of_says)\n",
    "ada_test_acc = adaboost_acc(X_test,y_test,stumps,feat_names, amount_of_says)\n",
    "\n",
    "print(f'adaboost ensemble accuracies, {ada_train_acc} train, {ada_test_acc} test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c918a41a-b105-4d38-9915-b998ec9c30b0",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03de5f-c402-4dc8-9442-e5a4c803b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = random_forest(X_train,\n",
    "                   y_train,\n",
    "                   feat_names,\n",
    "                   tree_count=500,\n",
    "                   max_depth=100, \n",
    "                   IG_metric='entropy')\n",
    "\n",
    "with open(f'./3/random_forest.pkl','wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b20dbd-e5aa-4896-a17b-93c101e2935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_acc = forest_acc(X_train,y_train,rf,feat_names)\n",
    "rf_test_acc = forest_acc(X_test,y_test,rf,feat_names)\n",
    "\n",
    "print(f'random forest accuracies {rf_train_acc} train, {rf_test_acc} test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe0edd4-ca8c-44ad-8340-fd98ac5925b4",
   "metadata": {},
   "source": [
    "### bagged forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5df49b-50b4-41a7-b754-d92cbaf620bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_forest = bagging(X_train,\n",
    "                        y_train,\n",
    "                        feat_names,\n",
    "                        tree_count=500,\n",
    "                        max_depth=100,\n",
    "                        IG_metric='entropy')\n",
    "\n",
    "with open(f'./3/bagged_forest.pkl','wb') as f:\n",
    "    pickle.dump(bagged_forest, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904e9f9-22b9-4166-9481-25aa8878fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bagged_train_acc = forest_acc(X_train,y_train,bagged_forest,feat_names)\n",
    "bagged_test_acc = forest_acc(X_test,y_test,bagged_forest,feat_names)\n",
    "\n",
    "print(f'bagged forest accuracies {bagged_train_acc} train, {bagged_test_acc} test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd3a606-b6d9-41c0-94d2-9eed2924c1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb17561-7897-4f1c-98f7-044fdb399d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opt",
   "language": "python",
   "name": "opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
